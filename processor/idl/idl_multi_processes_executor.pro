;  Copyright 2010, by the California Institute of Technology.  ALL RIGHTS
;  RESERVED. United States Government Sponsorship acknowledged. Any commercial
;  use must be negotiated with the Office of Technology Transfer at the
;  California Institute of Technology.
;
; $Id$
; DO NOT EDIT THE LINE ABOVE - IT IS AUTOMATICALLY GENERATED BY CM

;------------------------------------------------------------------------------------------------------------------------
FUNCTION _logger, $
             i_log_lun, $
             i_log_message

; Write i_log_message to file, assuming logical file unit is already opened with a time stamp in the beginning.

now_is = SYSTIME(/UTC);
printf, i_log_lun, now_is + ":" + i_log_message;
FLUSH, i_log_lun;  Because IDL buffers input and output, we wish to see the output of the log immediately so we must flush the buffer.
return, 1;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION create_clusterjob_directory, $
             i_unique_clusterjob_directory

; Function create a directory if it does not already exist.
; In any case, the original directory name is returned.
; This is a convenience function to make sure the directory exist before creating any new files beneath that directory.

if (i_unique_clusterjob_directory EQ "") then begin
    print, 'create_clusterjob_directory:ERROR, input variable i_unique_clusterjob_directory is empty string. Nothing to do.';
endif else begin
    if (FILE_TEST(i_unique_clusterjob_directory,/DIRECTORY) EQ 0) then begin
        FILE_MKDIR, i_unique_clusterjob_directory;
    endif
endelse
return, i_unique_clusterjob_directory;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION count_number_of_different_files_needing_to_ancillary_filled, $
             i_tasks_array, $
             io_signal_complete_command_string

; Loop through array i_tasks_array to find the number of different files needing to be ancillary filled.
;
; Assumptions:
;
; 1.  The strings representing the IDL program calls contains the correct format. 
;
; Note: the variable io_signal_complete_command_string is a way we can return multiple parameters back to callee.
;       This variable represent the task string the Ancillary Filling uses to signal that all the jobs for a particular batch is done.

tstart = systime(1)
;print, 'count_number_of_different_files_needing_to_ancillary_filled: execution start time:', systime()

@load_maf_constants

r_num_different_files = 0;

;
; Get size of input argument.
;

size_array = size(i_tasks_array);

; Info:
;
; [0] = number of dimensions 
; [1] = size of each dimension (one element per dimension] 

num_dimensions = size_array[0];
num_tasks      = size_array[1];

;help, num_dimensions
;help, num_tasks

EXPECTED_DIMENSIONS = 1;     The string array being passed in is only one dimension.

;
; Loop through each entry in the input array and pass the string to the worker.
;

DEFAULT_STAGE = 1;
EXPECTED_MAX_TOKENS = 2;

CLUSTER_JOB_STRING = "__clusterjob";  This is the convention used by Ancillary Filling to create temporary directory.  We look for this string.
;print, 'starting';

current_sequence_number = 0; 
previous_sequence_number = 0;

print, 'num_tasks ', num_tasks;

for task_num = 0, num_tasks - 1 do begin
  print, 'task_num ', task_num;

  ; Ignore zero size strings.
  if (STRLEN(i_tasks_array[task_num]) EQ 0) then begin
     print, "count_number_of_different_files_needing_to_ancillary_filled: ERROR, String is empty.  Nothing to do.";
     continue;
  endif

  ; Ignore jobs that has 'signal_complete' in it because we want to save it for the end.

  if (STRMATCH(i_tasks_array[task_num],'*signal_complete*')) then begin
     print, "count_number_of_different_files_needing_to_ancillary_filled: INFO, job named signal_complete do not count.";

     ; Before saving this task, we remove the ":4" (or any stage) from the string.
     splitted_array = STRSPLIT(i_tasks_array[task_num],":",/EXTRACT);

     print, "count_number_of_different_files_needing_to_ancillary_filled: INFO, Saving " +  splitted_array[0] + " to variable io_signal_complete_command_string.";

     ; Save this string to return back to called.
     io_signal_complete_command_string = splitted_array[0]; 
     continue;
  endif

  ; Get access to the "__clusterjob." substring so can get to the "1265822773.1" so we can get the next one "1265822773.2" in the next row.
  ;
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/DT_analysis.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_surface_temperature-fnmoc.nc",.1,0,-127,127,.1:4
  ;  lapinta{}% cat joblis | grep "1265822773\.2"
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/DT_analysis.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_surface_temperature-fnmoc.nc",.1,0,-127,127,.1:4
  ;

  pos_of_first_clusterjob = STRPOS(i_tasks_array[task_num],CLUSTER_JOB_STRING);

  if (pos_of_first_clusterjob EQ -1) then begin
     print, "count_number_of_different_files_needing_to_ancillary_filled: ERROR, Cannot find substring " + CLUSTER_JOB_STRING + " in string " + i_tasks_array[task_num];
     continue;
  endif
 
  ; Now that we have found the substring "__clusterjob.1265822773", we need to get to the digits immediately after the dot and before the slash.
  ; We do that by extracting the original string right after the dot by adding where __clusterjob was found, adding the length and 1 for the dot itself.

  string_start_of_seconds_since_1970 = STRMID(i_tasks_array[task_num],pos_of_first_clusterjob + STRLEN(CLUSTER_JOB_STRING) + 1);

  print, 'i_tasks_array[',i_tasks_array[task_num],']'
  print, 'string_start_of_seconds_since_1970[',string_start_of_seconds_since_1970,']';

  ; Now, we get the digits representing seconds since 1970.

  first_substring_seconds_since_1970 = STRMID(string_start_of_seconds_since_1970,0,STRPOS(string_start_of_seconds_since_1970,"/"));

  print ,'first_substring_seconds_since_1970 [' ,first_substring_seconds_since_1970, ']'

  ; Using this variable, first_substring_seconds_since_1970, we look for it again but this time, we are looking for the digits immediately after the dot.
  ; Let's call this a sequence_number

  pos_second_seconds_since_1970 = STRPOS(string_start_of_seconds_since_1970,first_substring_seconds_since_1970,1);  We want to get to the 2nd one, so can't start on the first one, must use 1.
  print ,'pos_second_seconds_since_1970 [' ,pos_second_seconds_since_1970, ']'

  ; We now get to the digit after the period after the seconds since 1970 of "sea_ice_fraction.1265822773.1",1'
  string_start_of_sequence_number  = STRMID(string_start_of_seconds_since_1970,pos_second_seconds_since_1970 + STRLEN(first_substring_seconds_since_1970) + 1);
  print ,'string_start_of_sequence_number [' ,string_start_of_sequence_number, ']'

  ; At this point, we need to get anything before the first double quote.

  sequence_number = STRMID(string_start_of_sequence_number,0,STRPOS(string_start_of_sequence_number,'"'));
  current_sequence_number = sequence_number;

  print ,'sequence_number [' ,sequence_number, ']'

  ;
  ; If the sequence numbers are different, we can bump up the count by 1.
  ;
  if (current_sequence_number NE previous_sequence_number) then begin
    r_num_different_files = r_num_different_files + 1;
    print ,'------ r_num_different_files replace previous_sequence_number with current_sequence_number -----';
    print ,'r_num_different_files [' ,r_num_different_files, ']';
    print ,'------ previous_sequence_number ', previous_sequence_number;
    print ,'------ current_sequence_number  ', current_sequence_number

    ; Reset the previous_sequence_number to current_sequence_number so we can detect when the sequence number changes.
    previous_sequence_number = current_sequence_number;
  endif

endfor

; Return the number of different files needing to be ancillary filled.

return, r_num_different_files;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION get_seconds_since_1970, $
             i_tasks_array

; Function parse through i_tasks_array for the substring representing seconds since 1970.
;
; Assumptions:
;
; 1.  The strings representing the IDL program calls contains the correct format. 
;

tstart = systime(1)
;print, 'idl_check_processing_strings_for_stages: execution start time:', systime()

@load_maf_constants

;SUCCESS = 0;
;FAILURE = 1;

r_seconds_since_1970 = "";  This is a string, not a number.

;
; Get size of input argument.
;

size_array = size(i_tasks_array);

; Info:
;
; [0] = number of dimensions 
; [1] = size of each dimension (one element per dimension] 

num_dimensions = size_array[0];
num_tasks      = size_array[1];

;help, num_dimensions
;help, num_tasks

EXPECTED_DIMENSIONS = 1;     The string array being passed in is only one dimension.

;
; Loop through each entry in the input array and pass the string to the worker.
;

;DEFAULT_STAGE = 1;
;EXPECTED_MAX_TOKENS = 2;

idl_command_str = ""; 
;largest_stage   = DEFAULT_STAGE;

task_saved = 0;
CLUSTER_JOB_STRING = "__clusterjob";
;print, 'starting';

; Just loop through once

for task_num = 0, 0 do begin
;  print, 'task_num ', task_num;

  if (STRLEN(i_tasks_array[task_num]) EQ 0) then begin
     print, "get_seconds_since_1970: ERROR, String is empty.  Nothing to do.";
     continue;
  endif

  ; Get access to the "__clusterjob." substring so can get to the "1265822773.1" so we can get the next one "1265822773.2" in the next row.

  ;  lapinta{}% cat joblis | grep "1265822773\.1"
  ;
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/DT_analysis.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_surface_temperature-fnmoc.nc",.1,0,-127,127,.1:4
  ;  lapinta{}% cat joblis | grep "1265822773\.2"
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
  ;  ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/DT_analysis.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_surface_temperature-fnmoc.nc",.1,0,-127,127,.1:4
  ;  lapinta{}% cat joblis | grep "1265822773\.3"

  pos_of_first_clusterjob = STRPOS(i_tasks_array[task_num],CLUSTER_JOB_STRING);

  if (pos_of_first_clusterjob EQ -1) then begin
     print, "get_seconds_since_1970: ERROR, Cannot find substring " + CLUSTER_JOB_STRING + " in string " + i_tasks_array[task_num];
     continue;
  endif
 
  ; Now that we have found the substring "__clusterjob.1265822773", we need to get to the digits immediately after the dot and before the slash.
  ; We do that by extracting the original string right after the dot by adding where __clusterjob was found, adding the length and 1 for the dot itself.

  string_start_of_seconds_since_1970 = STRMID(i_tasks_array[task_num],pos_of_first_clusterjob + STRLEN(CLUSTER_JOB_STRING) + 1);

  print, 'i_tasks_array[',i_tasks_array[task_num],']'
  print, 'string_start_of_seconds_since_1970[',string_start_of_seconds_since_1970,']';

  ; Now, we get the digits representing seconds since 1970.

  first_substring_seconds_since_1970 = STRMID(string_start_of_seconds_since_1970,0,STRPOS(string_start_of_seconds_since_1970,"/"));

  ; Sometimes, the task name can be 'signal_complete,"/home/qchau/ancillary_processing/data/__clusterjob.1266006274":5'
  ; In this case, we try STRMID again, but this time, we stop at the next double quote.
  if (first_substring_seconds_since_1970 EQ "") then begin
     first_substring_seconds_since_1970 = STRMID(string_start_of_seconds_since_1970,0,STRPOS(string_start_of_seconds_since_1970,'"'));
  endif

  ; Save this to return string and we are one.
  r_seconds_since_1970 = first_substring_seconds_since_1970;

  print ,'first_substring_seconds_since_1970 [' ,first_substring_seconds_since_1970, ']'
endfor

; Return the seconds since 1970 back to callee.

return, r_seconds_since_1970;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION dump_task_structure, $
             i_num_different_files, $
             i_sorted_granules_jobs

; Function dump the task structure for inspection, a good debugging tool.
; 

MAX_NUM_DIFFERENT_ANCILLARY_DATA_TYPES = 6; This is defined else where in this file.
print, '--------------------------------------------------------------------------------'
print, 'Dumping variable i_sorted_granules_jobs for inspection.'
print, '--------------------------------------------------------------------------------'
for outer_loop = 0, i_num_different_files - 1 do begin
    print, 'outer_loop:', outer_loop;
    task_index = 0;

    for task_index = 0, MAX_NUM_DIFFERENT_ANCILLARY_DATA_TYPES - 1 do begin
        if (STRLEN(i_sorted_granules_jobs[outer_loop].m_tasks_array[task_index]) GT 0) then begin
            print, '    inner_loop:', task_index, ', value = [', i_sorted_granules_jobs[outer_loop].m_tasks_array[task_index], ']';
        endif
    endfor
endfor
return, 1;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION idl_multi_sort_similar_granules_jobs, $
             i_tasks_array, $
             io_signal_complete_command_string, $
             io_unique_clusterjob_directory, $
             io_seconds_since_1970, $
             io_log_lun

; Function sort similar granules together and return the structure r_sorted_granules_jobs representing the jobs that are similar.
;
; Assumptions:
;
; 1.  The strings representing the IDL program calls contains the correct format. 
;

tstart = systime(1)
;print, 'idl_check_processing_strings_for_stages: execution start time:', systime()

@load_maf_constants

;SUCCESS = 0;
;FAILURE = 1;

over_all_status = SUCCESS; 

;
; Get size of input argument.
;

size_array = size(i_tasks_array);

; Info:
;
; [0] = number of dimensions 
; [1] = size of each dimension (one element per dimension] 

num_dimensions = size_array[0];
num_tasks      = size_array[1];

; We allocate as many strings needed to return the sorted array of strings.

r_tasks_array = STRARR(num_tasks);

;help, num_dimensions
;help, num_tasks

EXPECTED_DIMENSIONS = 1;     The string array being passed in is only one dimension.

;
; Loop through each entry in the input array and pass the string to the worker.
;

CLUSTER_JOB_STRING = "__clusterjob";

print, 'starting idl_multi_sort_similar_granules_jobs';
print, 'idl_multi_sort_similar_granules_jobs:num_tasks = ', num_tasks;

current_search_key = "CURRENT_SEARCH_KEY";

;
; These variable will be returned to callee.
;
io_signal_complete_command_string = "DUMMY";
io_unique_clusterjob_directory    = "DUMMY";

o_num_different_files = count_number_of_different_files_needing_to_ancillary_filled(i_tasks_array,io_signal_complete_command_string);
o_seconds_since_1970  = get_seconds_since_1970(i_tasks_array);
; Also save this so we can return it.
io_seconds_since_1970  = o_seconds_since_1970

; Save these variables to return to callee.
;
; This directory will be used to create temporary working files and such.
; The logical unit will be used to provide a way to log this run.

io_unique_clusterjob_directory = GETENV('HOME') + "/task_farm_output/" + CLUSTER_JOB_STRING + "." + o_seconds_since_1970; 

; Open a logger file and return the logical unit to callee.
; Note:
;
;   1. At this point, the directory io_unique_clusterjob_directory has not been created, we must create it with create_clusterjob_directory() function.
;   2. The temporary name starts with tmp_idl so it will be easier to find a list of these temporary files for deletion later on.

OPENW, io_log_lun, create_clusterjob_directory(io_unique_clusterjob_directory) + '/tmp_idl_a_multi_jobs_one_process_log.log', /GET_LUN, ERROR = err_no;

; If err_no is nonzero, something happened. Print the error message to  
; the standard error file (logical unit -2): 
if  (err_no NE 0) then begin
    PRINTF, -2, 'idl_multi_sort_similar_granules_jobs:' + !ERROR_STATE.MSG 
    ; At this point, it may be prudent to return since it is not possible to perform any logging because the io_log_lun is now an invalid number.
    r_sorted_granules_jobs = "";  An empty string signify that something is wrong.
    return, r_sorted_granules_jobs;
endif


; Now that we know what is the seconds since 1970 is, we can search through the task list again to find similar
; sequence number.  For example lines 1, 9, and 17 will be group together because they have "1265822773.1":

;  1 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  2 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  3 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.3",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  4 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.4",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  5 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.5",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  6 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.6",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  7 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.7",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  8 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/sea_ice_fraction.1265822773.8",1,"/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc",0.004,0.5,-125,125,1:1
;  9 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 10 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 11 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.3",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 12 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.4",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 13 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.5",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 14 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.6",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 15 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.7",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 16 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/surface_solar_irradiance.1265822773.8",1,"/home/qchau/ancillary_processing/ancillary/maf-surface_solar_irradiance-ecmwf.nc",4,508,-127,127,1:2
; 17 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.1",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
; 18 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.2",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
; 19 ancillary_filler,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773/wind_speed.1265822773.3",1,"/home/qchau/ancillary_processing/ancillary/maf-wind_speed-ecmwf.nc",.25,31.75,-127,127,1:3
; 20 signal_complete,"/home/qchau/ancillary_processing/data/__clusterjob.1265822773":4

task_saved = 0;
print ,'   SECOND LOOPING TO SEARCH FOR SIMILAR SEQUENCE '; 
print ,'   o_num_different_files ', o_num_different_files;
print ,'   o_seconds_since_1970  ', o_seconds_since_1970;

donotcare = _logger(io_log_lun,'   SECOND LOOPING TO SEARCH FOR SIMILAR SEQUENCE '); 
donotcare = _logger(io_log_lun,'   o_num_different_files ' + STRING(o_num_different_files));
donotcare = _logger(io_log_lun,'   o_seconds_since_1970  ' + STRING(o_seconds_since_1970));

;
; Create a structure to return to callee.
;

MAX_NUM_DIFFERENT_ANCILLARY_DATA_TYPES = 6;
jobs_variable_str = { m_tasks_array: STRARR(MAX_NUM_DIFFERENT_ANCILLARY_DATA_TYPES) }  ; We allocate at most 6 strings per structure.  Each string represent one ancillary filling and there are at most 6 ancillary data types.

; Create an array of at most many different files to process.
; The variable o_num_different_files is at most 8.

r_sorted_granules_jobs = REPLICATE(jobs_variable_str, o_num_different_files);

; Create an outer loop as to how many times to loop through the i_tasks_array to look for a specific sequence number.

for outer_loop = 0, LONG(o_num_different_files) - 1 do begin
    print ,'>> outer_loop [' ,outer_loop, ']';
    donotcare = _logger(io_log_lun,'>> outer_loop [' + STRING(outer_loop) + ']');

    ; For each outer loop, we loop through all the tasks to look for the combination of the seconds since 1970, and the sequence number.
    ; Make sure to remove the leading and trailing blanks when converting a LONG (outer_loop variable) to STRING.

    current_search_key = o_seconds_since_1970 + "." + STRTRIM(STRING(outer_loop + 1),2);
    print ,'   current_search_key [' ,current_search_key, ']';
    donotcare = _logger(io_log_lun,'   current_search_key ['  + STRING(current_search_key) + ']');

    task_saved = 0;

    for task_num = 0, num_tasks - 1 do begin
      if (STRPOS(i_tasks_array[task_num],current_search_key) GE 0) then begin
          ; We have a found a task with the search key, i.e. same seconds since 1970 and ".n".
          ; Before saving the task name, we strip the ":1" from the string
          r_sorted_granules_jobs[outer_loop].m_tasks_array[task_saved] = STRMID(i_tasks_array[task_num],0,STRPOS(i_tasks_array[task_num],":"));
          print ,'   >>> r_sorted_granules_jobs [' ,r_sorted_granules_jobs[outer_loop].m_tasks_array[task_saved], ']';
          donotcare = _logger(io_log_lun,'   >>> r_sorted_granules_jobs [' + r_sorted_granules_jobs[outer_loop].m_tasks_array[task_saved] + ']');
;          r_tasks_array[task_saved] = i_tasks_array[task_num];
;          print ,'   >>> r_tasks_array[' ,r_tasks_array[task_saved], ']';
          task_saved = task_saved + 1;
;          print ,'   >>> task_saved [' ,task_saved, ']';
      endif
    endfor; for task_num = 0, num_tasks - 1 do begin

endfor; for outer_loop = 0, LONG(o_num_different_files) - 1

; Return data structure containing the list of jobs to be processed grouped by files to fill.
help, r_sorted_granules_jobs, /str;

; Next call can be commented out without affecting the normal operation of the code.

donotcare = dump_task_structure(o_num_different_files, r_sorted_granules_jobs);
;print, 'idl_multi_sort_similar_granules_jobs: exiting IDL for now.';
;EXIT;

return, r_sorted_granules_jobs;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION replace_double_with_single_quotes, $
             i_instring

   ; Function replaces any double quotes with single quotes.
   ;
   ; If i_instring does not contain any double quotes, the string returned is the same string.
   ;
   ; The strategy:
   ;
   ;    1.  Convert the string into byte representation as an array.
   ;    2.  For each byte, we inspect it to see if it is a double quote.
   ;    3.  If it is, we replace it with single quote.
   ;    4.  If it is not a double quote, we save the byte as is.
   ;    5.  At the end, convert this to a string array and return it.


   num_characters = STRLEN(i_instring);

   ; Save the string as byte array.

   original_string_as_bytes_array = BYTE(i_instring);
   resultant_string_as_bytes_array = BYTARR(num_characters);

   ;print, 'replace_double_with_single_quotes:num_characters ', num_characters;
  
   ; Note:
   ;
   ;    Must use the BYTE() function to convert the single/double quote to compare to element in resultant_string_as_bytes_array array.
   ;

   DOUBLE_QUOTE = BYTE('"');
   SINGLE_QUOTE = BYTE("'");

   for str_index = 0, (num_characters - 1) do begin
       if (original_string_as_bytes_array[str_index] EQ DOUBLE_QUOTE) then begin
           resultant_string_as_bytes_array[str_index]  = SINGLE_QUOTE;  Replace double quote with single quote.
       endif else begin
           resultant_string_as_bytes_array[str_index] = original_string_as_bytes_array[str_index]; Keep as original character.
       endelse
   endfor

   ; Combine all the bytes together and convert back to a string to return.

   return, STRING(resultant_string_as_bytes_array);
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION idl_check_processing_strings_for_stages, $
             i_tasks_array

; Function loop through each strings in i_tasks_array for substring at the end that are greater than ":1"
; If any of the strings in i_tasks_array has ":2" or greater, return true, else return false.
;
; Assumptions:
;
; 1.  The strings representing the IDL program calls contains the correct format. 
;

tstart = systime(1)
print, 'idl_check_processing_strings_for_stages: execution start time:', systime()

@load_maf_constants

;SUCCESS = 0;
;FAILURE = 1;

over_all_status = SUCCESS; 
r_tasks_array_depends_on_stage = 0;  Set to 1 if the i_task_array contains stages greater than 1.

;
; Get size of input argument.
;

size_array = size(i_tasks_array);

; Info:
;
; [0] = number of dimensions 
; [1] = size of each dimension (one element per dimension] 

num_dimensions = size_array[0];
num_tasks      = size_array[1];

;help, num_dimensions
;help, num_tasks

EXPECTED_DIMENSIONS = 1;     The string array being passed in is only one dimension.

;
; Loop through each entry in the input array and pass the string to the worker.
;

DEFAULT_STAGE = 1;
EXPECTED_MAX_TOKENS = 2;

idl_command_str = ""; 
stage_number    = 0;
largest_stage   = DEFAULT_STAGE;

for task_num = 0, num_tasks - 1 do begin

  ; Split the processing job on ":".  The stage number is to the right of ":". 

;  i_tasks_array[task_num] = i_tasks_array[task_num] + ":5";
  splitted_array = STRSPLIT(i_tasks_array[task_num],":",/EXTRACT);  

  num_tokens = size(splitted_array,/N_ELEMENTS);

  ; Handle the case where the stage is not specified.

  if (num_tokens EQ 1) then begin
      ;
      ; No stage is given, the element in i_tasks_array[task_num] is the task itself. 
      ; Set the stage_number to the default stage.
      ;
      idl_command_str = splitted_array[0];
      stage_number    = DEFAULT_STAGE;
;print, 'idl_check_processing_strings_for_stages:idl_command_str = [',idl_command_str,']'
;print, 'idl_check_processing_strings_for_stages:stage_number    = [',stage_number,']'
  endif else begin

      ;
      ; We get 2 tokens, get the job and the stage number.
      ;

      if (num_tokens EQ EXPECTED_MAX_TOKENS) then begin
          idl_command_str =     splitted_array[0]; 
          stage_number    = FIX(splitted_array[1]);  Must convert the stage from string to integer.

          ; Keep track of the largest stage number for use in advancing the stage.
          if (stage_number GT largest_stage) then begin
              largest_stage = stage_number;
          endif
      endif else begin
          ;
          ; More than 2 tokens is an error.
          ;
          print, 'idl_check_processing_strings_for_stages: ERROR, Only expecting ', EXPECTED_MAX_TOKENS, ' tokens from the task array.';
          print, 'idl_check_processing_strings_for_stages: num_tokens = ', num_tokens; 

          l_status = error_log_writer($
               'idl_check_processing_strings_for_stages',$
               'num_tokens = ' + STRTRIM(STRING(num_tokens),2) + $
               ' expected = ' +  STRTRIM(STRING(EXPECTED_MAX_TOKENS),2));

          over_all_status = FAILURE; 
          return, over_all_status;
      endelse
  endelse

endfor

print, 'idl_check_processing_strings_for_stages: largest_stage = ', largest_stage; 
if (largest_stage GT 1) then begin
    r_tasks_array_depends_on_stage = 1;
endif
print, 'Overall execution time:', systime(1) - tstart
help,/heap

;
; Close up shop.
;

return, r_tasks_array_depends_on_stage;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION build_command_string, $
             i_task_name

; Function receive a task name and returns a command string.
;
; 1.  The strings representing the IDL program calls contains the correct format. 
;

tstart = systime(1)
;print, 'build_command_string: execution start time:', systime()

@load_maf_constants

r_idl_command_str = "";

DEFAULT_STAGE = 1;
EXPECTED_MAX_TOKENS = 2;
stage_number    = 0;

; Split the processing job on ":".  The stage number is to the right of ":". 

splitted_array = STRSPLIT(i_task_name,":",/EXTRACT);  
  
num_tokens = size(splitted_array,/N_ELEMENTS);

; Handle the case where the stage is not specified.

if (num_tokens EQ 1) then begin
    ;
    ; No stage is given, the element in i_tasks_array[task_num] is the task itself. 
    ; Set the stage_number to the default stage.
    ;
    r_idl_command_str = splitted_array[0];
    stage_number    = DEFAULT_STAGE;
;print, 'build_command_string:r_idl_command_str = [',r_idl_command_str,']'
;print, 'build_command_string:stage_number    = [',stage_number,']'
endif else begin

    ;
    ; We get 2 tokens, get the job and the stage number.
    ;

    if (num_tokens EQ EXPECTED_MAX_TOKENS) then begin
        r_idl_command_str =     splitted_array[0]; 
        stage_number    = FIX(splitted_array[1]);  Must convert the stage from string to integer.
    endif else begin
        ;
        ; More than 2 tokens is an error.
        ;
        print, 'build_command_string: ERROR, Only expecting ', EXPECTED_MAX_TOKENS, ' tokens from the task array.';
        print, 'build_command_string: num_tokens = ', num_tokens; 

        l_status = error_log_writer($
                      'build_command_string',$
                      'num_tokens = ' + STRTRIM(STRING(num_tokens),2) + $
                      ' expected = ' +  STRTRIM(STRING(EXPECTED_MAX_TOKENS),2));
       
        over_all_status = FAILURE; 
        return, over_all_status;
    endelse
endelse

;------------->
if (2 EQ 3) then begin
  ; Parse the procedure name and all the parameters into a long string separated by spaces.

  called_tokens = STRSPLIT(r_idl_command_str,",",/EXTRACT);  
  
  num_tokens = size(called_tokens,/N_ELEMENTS);

  SYSTEM_COMMAND_PARTIAL_STRING = "idl_one_process_executor.sav -args ";
  operating_system_command = SYSTEM_COMMAND_PARTIAL_STRING;
  arguments_string = '';
  token_minus_single_quotes = '';
  token_with_single_quotes = '';
  arguments_with_quotes_string = '';

  ;
  ; Now loop through all the tokens and add the parameters.
  ;

  for token_count = 1, num_tokens - 1 do begin
      ; Remove the single quotes from each token (read first and last character).
      ;
      ; Note: This is making a big assumption that each token is surrounded by a single quote.
      ;       There may be a case that the token is an integer.  For the time being, Ancillary Filling
      ;       only has character parameters.

      token_minus_single_quotes = STRMID(called_tokens[token_count],1,STRLEN(called_tokens[token_count]) - 2);
      arguments_string = arguments_string + token_minus_single_quotes + ' ';

      ; Add a comma if is not the first parameter.
      if (token_count EQ 1) then begin
          token_with_single_quotes = called_tokens[token_count];
      endif else begin
          token_with_single_quotes = ',' + called_tokens[token_count];
      endelse
      arguments_with_quotes_string = arguments_with_quotes_string + token_with_single_quotes + ' ';
;      arguments_string = arguments_string + '"' + token_minus_single_quotes + '"' + ' ';
;      token_minus_single_quotes = called_tokens[token_count];
;      arguments_string = arguments_string + '"' + token_minus_single_quotes + '"' + ' ';
  endfor
  
  ; Build the command we will be sending to the operating system.  Add the '&' so it will return immediately.
  ;operating_system_command = operating_system_command + '"' + arguments_string + '"' + " & "; 

;print, 'PRE replace_double_with_single_quotes r_idl_command_str [' + idl_command_str + ']';
endif
;<-----------

  ; Because the Ancillary Filling may use double quotes, we replace double quotes with single quotes.

  r_idl_command_str = replace_double_with_single_quotes(r_idl_command_str);

;print, 'POST replace_double_with_single_quotes r_idl_command_str [' + r_idl_command_str + ']';

  return, r_idl_command_str
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION parse_job_for_clusterjob_directory_name, $
             i_task_name

; Function parse ancillary_filler,'/home/qchau/ancillary_processing/data/__clusterjob.1266019612/sea_ice_fraction.1266019612.1',1,'/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc',0.004,0.5,-125,125,1
; for the directory name '[ancillary_filler,/home/qchau/ancillary_processing/data/__clusterjob.1266019612/sea_ice_fraction.1266019612.1'
; i_task_name = "ancillary_filler,'/home/qchau/ancillary_processing/data/__clusterjob.1266019612/sea_ice_fraction.1266019612.1',1,'/home/qchau/ancillary_processing/ancillary/maf-sea_ice_fraction-ecmwf.nc',0.004,0.5,-125,125,1"

r_clusterjob_directory_name = "";

splitted_string = STRSPLIT(i_task_name,',',/EXTRACT);
second_token = splitted_string[1]; 
token_without_quotes = STRMID(second_token,1,(STRLEN(second_token) - 2));  We now have /home/qchau/ancillary_processing/data/__clusterjob.1266019612/sea_ice_fraction.1266019612.1

; Strip everything after the last slash and we have the directory name.

r_clusterjob_directory_name = STRMID(token_without_quotes,0,STRPOS(token_without_quotes,'/',/REVERSE_SEARCH));
return, r_clusterjob_directory_name
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION idl_execute_sorted_similar_granules_jobs, $
             i_sorted_granules_jobs, $
             i_signal_complete_command_string, $
             i_unique_clusterjob_directory, $
             i_seconds_since_1970, $
             i_log_lun

; Function receive a structure containing array of jobs of similar granules that need ancillary filling.
; These jobs can then be farmed out as sub processes via the SPAWN command.

@cluster_management.cfg

over_all_status = SUCCESS;

print ,'idl_execute_sorted_similar_granules_jobs:N_ELEMENTS(i_sorted_granules_jobs) [',N_ELEMENTS(i_sorted_granules_jobs),']';
number_of_different_files = N_ELEMENTS(i_sorted_granules_jobs);

; For every different file, we send the list of via a file, containig jobs to one machine (one process) to execute.
SYSTEM_COMMAND_PARTIAL_STRING = "idl_many_jobs_one_process_executor.sav -args ";
MAX_NUM_DIFFERENT_ANCILLARY_DATA_TYPES = 6; This is defined elsewhere in this file.

print ,'idl_execute_sorted_similar_granules_jobs:number_of_different_files ',number_of_different_files;
;o_clusterjob_directory_name = ""; 

names_of_sentinel_of_finished_jobs = STRARR(number_of_different_files);
filename_job_lists_from_ancillary_filling_process = "";

actual_num_files = 0; We increment this if there is at least one task in the structure i_sorted_granules_jobs.

lun = 99999; Need some sort of logical number for each file_num loop.

for file_num = 0, number_of_different_files - 1 do begin
    ; For each file, we extract as many strings and write them to a file.

    found_first_name = 0;

    for task_num = 0, (MAX_NUM_DIFFERENT_ANCILLARY_DATA_TYPES - 1) do begin

        ; We only process non-zeroed size strings

        if ((STRLEN(i_sorted_granules_jobs[file_num].m_tasks_array[task_num])) GT 0) then begin

            ; Replace the double quotes with single quotes because IDL does not like double quotes in runtime execution.
            o_task_string_with_single_quotes = replace_double_with_single_quotes(i_sorted_granules_jobs[file_num].m_tasks_array[task_num]);

;print, 'idl_execute_sorted_similar_granules_jobs:file_num [',file_num,']';
;print, 'idl_execute_sorted_similar_granules_jobs:task [',o_task_string_with_single_quotes,']';
;print, 'idl_execute_sorted_similar_granules_jobs:found_first_name [',found_first_name,']';

             ; If we haven't found a directory name yet, we will search for it
             if (found_first_name EQ 0) then begin

                 ; Create a file to save the IDL jobs to be processed.

                 filename_job_lists_from_ancillary_filling_process = create_clusterjob_directory(i_unique_clusterjob_directory) + '/tmp_idl_job_lists_from_ancillary_filling_process_' + STRTRIM(STRING(file_num+1),2) + '.dat';
                 OPENW, lun, filename_job_lists_from_ancillary_filling_process, /GET_LUN;

                 ;o_clusterjob_directory_name = parse_job_for_clusterjob_directory_name(o_task_string_with_single_quotes);
                 found_first_name = 1;

                 ; Save this directory along with a name so we can indicate that this job is done.
;                 names_of_sentinel_of_finished_jobs[file_num] = o_clusterjob_directory_name + "/tmp_idl_partial_job_" + STRTRIM(STRING(file_num+1),2) + "_complete";
                 names_of_sentinel_of_finished_jobs[file_num] = create_clusterjob_directory(i_unique_clusterjob_directory) + "/tmp_idl_partial_job_complete_"  + STRTRIM(STRING(file_num+1),2);

;print, 'idl_execute_sorted_similar_granules_jobs:names_of_sentinel_of_finished_jobs [',names_of_sentinel_of_finished_jobs[file_num],']';
 
                 ; Don't forget to keep track of how many actual files we have found.
                 actual_num_files = actual_num_files + 1;

             endif; if (found_first_name EQ 0)

             ; Here, we assume the file has been opened, we just need to save this task to file.

;print, 'idl_execute_sorted_similar_granules_jobs: writing to file [',o_task_string_with_single_quotes,']';
             printf, lun, o_task_string_with_single_quotes;

        endif; if ((STRLEN(i_sorted_granules_jobs[file_num].m_tasks_array[task_num])) GT 0)
    endfor; for task_num = 0, 5

    ; Close up shop if opened shop.
    if (found_first_name EQ 1) then begin
        FREE_LUN, lun, /FORCE;
    endif
 
    ; Now, pass this file into the program idl_many_subprocesses_executor.sav PROgram
    ; if we did indeed found at least one task.

    if (found_first_name EQ 1) then begin
        SPAWN, "cat " + filename_job_lists_from_ancillary_filling_process, run_output;
        donotcare = _logger(i_log_lun,'idl_execute_sorted_similar_granules_jobs:starting job #' + STRTRIM(STRING(file_num + 1)) + ' at (UTC): ' + SYSTIME(/UTC));
        donotcare = _logger(i_log_lun,'idl_execute_sorted_similar_granules_jobs:filename_job_lists_from_ancillary_filling_process = ' + filename_job_lists_from_ancillary_filling_process);
        system_call_string = "idl -quiet -rt=" + SYSTEM_COMMAND_PARTIAL_STRING + ' "' + filename_job_lists_from_ancillary_filling_process + '"' + ' ' + '"' + names_of_sentinel_of_finished_jobs[file_num] + '"' + ' ' + i_seconds_since_1970 + ' & '; 
        donotcare = _logger(i_log_lun,'idl_execute_sorted_similar_granules_jobs: SPAWN with system_call_string [' + system_call_string + ']');

        SPAWN, system_call_string, spawn_result, spawn_error;

        if (STRLEN(spawn_error) GT 0) then begin
            donotcare = idl_email_ops_to_report_error(idl_prepare_email_body(system_call_string));
        endif

        ; NOTE:
        ;
        ; We need to wait about 3 seconds in between execution to give the SPAWN command a chance to read the file in variable filename_job_lists_from_ancillary_filling_process.
        ; Eventhough each temporary file has unique names, it is a good idea to give the SPAWN function time to return.

        print, 'idl_execute_sorted_similar_granules_jobs: WAIT 3 seconds...';
        WAIT, 3;
    endif

endfor; for file_num = 0, number_of_different_files - 1

;------------------------------------------------------------------------------------------------
; If we actually farmed out jobs to do, we check for their completion.  Otherwise, nothing to do.
;------------------------------------------------------------------------------------------------

if (actual_num_files GT 0) then begin
    ; Now that all the jobs have been SPAWN out, we SPAWN another job to check for completion of the previous jobs.
    ;
    i_signal_complete_command_string =  replace_double_with_single_quotes(i_signal_complete_command_string);
    print, 'idl_execute_sorted_similar_granules_jobs: i_signal_complete_command_string [' + i_signal_complete_command_string + ']';
    donotcare = _logger(i_log_lun,'idl_execute_sorted_similar_granules_jobs: i_signal_complete_command_string [' + i_signal_complete_command_string + ']');

    ; Wait 5 seconds before doing checking for job completion.

    WAIT, 5;
    filename_partial_job_completion_filelist =  create_clusterjob_directory(i_unique_clusterjob_directory) + '/tmp_idl_job_completion_list.dat';
    OPENW, lun, filename_partial_job_completion_filelist, /GET_LUN;

    for file_num = 0, number_of_different_files - 1 do begin
        if (names_of_sentinel_of_finished_jobs[file_num] NE "") then begin
            printf, lun, names_of_sentinel_of_finished_jobs[file_num];
        endif
    endfor

    ; Close up shop.
    FREE_LUN, lun, /FORCE;

    ; For every different file, we send the list of via a file, containing jobs to one machine (one process) to execute.

    SYSTEM_COMMAND_CHECK_JOB_COMPLETION = "idl_monitor_jobs_completion.sav -args ";

    SPAWN, "cat " + filename_partial_job_completion_filelist;

    donotcare = _logger(i_log_lun,'idl_execute_sorted_similar_granules_jobs: filename_partial_job_completion_filelist [' + filename_partial_job_completion_filelist + ']');

    system_call_string = "idl -quiet -rt=" + SYSTEM_COMMAND_CHECK_JOB_COMPLETION + ' "' + filename_partial_job_completion_filelist + '"' + ' ' + '"' + i_signal_complete_command_string + '"' + ' ' + '"' + i_unique_clusterjob_directory + '"' + ' & '; 
    donotcare = _logger(i_log_lun,'idl_execute_sorted_similar_granules_jobs: SPAWN with system_call_string [' + system_call_string + ']');
    SPAWN, system_call_string, spawn_result, spawn_error;

    if (STRLEN(spawn_error) GT 0) then begin
        donotcare = idl_email_ops_to_report_error(idl_prepare_email_body(system_call_string));
    endif

;    SPAWN, "idl -quiet -rt=" + SYSTEM_COMMAND_CHECK_JOB_COMPLETION + ' "' + filename_partial_job_completion_filelist + '"' + ' ' + '"' + i_signal_complete_command_string + '"' + ' ' + '"' + i_unique_clusterjob_directory + '"' + ' & '; 

endif

; At this point, we are closing the log file so it can be removed by the program idl_monitor_jobs_completion.sav.  No further logging will be allowed.
FREE_LUN, i_log_lun, /FORCE;

return, over_all_status;
END

;------------------------------------------------------------------------------------------------------------------------
FUNCTION idl_multi_processes_executor, $
             i_tasks_array, $
             i_use_cluster_flag

; Function receives an array of strings containing IDL programs to be executed as sub processes on single node machine. 
; If any of the strings in i_tasks_array has ":2" or greater, they will be grouped together and similar the jobs (same granule) will be execute sequentially.
;
; Assumptions:
;
; 1.  The strings representing the IDL program calls contains the correct format. 
; 2.  If the environment GAPFARMUSEMULTIPROCESSESEXECUTOR is set to TRUE, we farm out the jobs to sub processes.

tstart = systime(1)
print, 'idl_multi_processes_executor: execution start time:', systime()

@load_maf_constants

over_all_status = SUCCESS;

; Check to see if the tasks in the array has a dependency on stage or not.

o_tasks_array_depends_on_stage = idl_check_processing_strings_for_stages(i_tasks_array);

;-------------------------------------------------------------------------------------------------------------------------------------
; This is another the big runtime SWITCH.  Only the Ancillary Filling Processing uses
; the "stage" idea.  The MODIS L2P will proceed as normal after the endif statement. 
;-------------------------------------------------------------------------------------------------------------------------------------

if (o_tasks_array_depends_on_stage EQ 1) then begin

    o_sorted_granules_jobs = idl_multi_sort_similar_granules_jobs(i_tasks_array,ret_signal_complete_command_string,ret_unique_clusterjob_directory,ret_seconds_since_1970,ret_log_lun);

    ;
    ; Only proceed if a valid structure is returned, signified by having a non-zero dimension.
    ;

    if (SIZE(o_sorted_granules_jobs,/N_DIMENSIONS) NE 0) then begin
        ; Note: the log file will be closed in idl_execute_sorted_similar_granules_jobs() function so it can be removed by the same function.
        ; After the execution of idl_execute_sorted_similar_granules_jobs(), the logical number ret_log_lun is no longer and file associated with this number is either closed or deleted.

        ;
        ; Everything is OK, we proceed to execute these IDL programs.
        ;

        over_all_status = idl_execute_sorted_similar_granules_jobs(o_sorted_granules_jobs,ret_signal_complete_command_string,ret_unique_clusterjob_directory,ret_seconds_since_1970,ret_log_lun);

    endif else begin
        over_all_status = FAILURE;
    endelse

    return, over_all_status;
endif

;exit;

; Normal MODIS L2P processing or if the Ancillary Filling does not have any stage greater than ":1" in the task string.

;
; Get size of input argument.
;

size_array = size(i_tasks_array);

; Info:
;
; [0] = number of dimensions 
; [1] = size of each dimension (one element per dimension] 

num_dimensions = size_array[0];
num_tasks      = size_array[1];

;help, num_dimensions
;help, num_tasks

EXPECTED_DIMENSIONS = 1;     The string array being passed in is only one dimension.

;
; Return immediately if the string array does not contain the correct dimension.
;

if (num_dimensions NE EXPECTED_DIMENSIONS) then begin
    print, 'idl_multi_processes_executor: ERROR, The input string is of incorrect dimension.';
    print, 'idl_multi_processes_executor: num_dimensions      = ', num_dimensions; 
    print, 'idl_multi_processes_executor: EXPECTED_DIMENSIONS = ', EXPECTED_DIMENSIONS;

    help, i_tasks_array;

    l_status = error_log_writer($
        'idl_multi_processes_executor',$
        'i_tasks_array num_dimensions = ' + STRTRIM(STRING(num_dimensions),2) + $
        ' expected = ' +  STRTRIM(STRING(EXPECTED_DIMENSIONS),2));

    over_all_status = FAILURE; 
    return, over_all_status;
endif

;
; Loop through each entry in the input array and pass the string to the worker via the SPAWN function.
;

SYSTEM_COMMAND_PARTIAL_STRING = "idl_one_process_executor.sav -args ";

idl_command_str = ""; 
operating_system_command = "";

for task_num = 0, num_tasks - 1 do begin

  ; Build the command strings such as removing double to single quotes to get ready to
  ; pass the command to the operating system.

  o_idl_command_str =  build_command_string(i_tasks_array[task_num]);
 
;  operating_system_command = SYSTEM_COMMAND_PARTIAL_STRING;

;print, 'POST replace_double_with_single_quotes o_idl_command_str [' + o_idl_command_str + ']';

  ; For now, set to MAKE_USE_CLUSTER_IF_AVAILABLE if user has not pass in the parameter,
  ; as in the case of the Ancillary Filling processing.

  if (N_ELEMENTS(i_use_cluster_flag) EQ 0) then begin
      i_use_cluster_flag = 'MAKE_USE_CLUSTER_IF_AVAILABLE';
;      print, 'idl_multi_processes_executor: INFO, Reset i_use_cluster_flag to ', i_use_cluster_flag; 
  endif

;print, 'i_use_cluster_flag = [',i_use_cluster_flag,']';

  ; If the user uses ":n" where n is greater than 1, we must SPAWN the jobs but in sequential.
print, 'idl_multi_processes_executor:o_tasks_array_depends_on_stage [',o_tasks_array_depends_on_stage,']';
print, 'idl_multi_processes_executor:i_use_cluster_flag [',i_use_cluster_flag,']';

  if ((o_tasks_array_depends_on_stage EQ 1) OR (i_use_cluster_flag NE 'MAKE_USE_CLUSTER_IF_AVAILABLE')) then begin
      ;operating_system_command = operating_system_command + '"' + o_idl_command_str + '"';
      if (o_tasks_array_depends_on_stage EQ 1) then begin
          operating_system_command = SYSTEM_COMMAND_PARTIAL_STRING + '"' + o_idl_command_str + '"';
      endif else begin
          ; We check to see if the environment GAPFARMUSEMULTIPROCESSESEXECUTOR is set.  If it is not set, we
          ; just execute the jobs sequentially.  If it is set, we have a 2nd opportunity to run the jobs
          ; as sub processes.
          if (STRUPCASE(GETENV('GAPFARMUSEMULTIPROCESSESEXECUTOR')) EQ 'TRUE') then begin
              operating_system_command = SYSTEM_COMMAND_PARTIAL_STRING + '"' + o_idl_command_str + '"' + " & ";
          endif else begin
              operating_system_command = SYSTEM_COMMAND_PARTIAL_STRING + '"' + o_idl_command_str + '"';
          endelse
      endelse
  endif else begin
      ; If the user does NOT use ":n" where n is greater than 1, we can SPAWN the jobs as detached sub processes.
      if (i_use_cluster_flag EQ 'MAKE_USE_CLUSTER_IF_AVAILABLE') then begin
          ;operating_system_command = operating_system_command + '"' + idl_command_str + '"' + " & "; 
          operating_system_command = SYSTEM_COMMAND_PARTIAL_STRING + '"' + o_idl_command_str + '"' + " & "; 
;print, 'idl_multi_processes_executor:CALLING SPAWN DETACHED PROCESSES';
      endif
  endelse

  print, 'OPERATING_SYSTEM_COMMAND [', operating_system_command, ']';

print, "idl -quiet -rt=" + operating_system_command + "]";

  ; Now, execute the IDL program with the strings we've built above..
  ;
  ; Note: If the system command has the ampersand '&' at the end, the spawn_result and spawn_error may not have the correct result
  ;       so their values are not as reliable to be inspected.
  ;       For now, we assume the SPAWN function works.

  SPAWN, "idl -quiet -rt=" + operating_system_command, spawn_result, spawn_error;

endfor

;print, 'Overall execution time:', systime(1) - tstart
;help,/heap

;
; Close up shop.
;

return, over_all_status;
END
